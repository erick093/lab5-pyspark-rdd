{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# download our dataset tiny-shakespeare.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\r\n",
      "--2022-12-14 13:09:58--  https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘datasets/tiny-shakespeare.txt’\r\n",
      "\r\n",
      "tiny-shakespeare.tx 100%[===================>]   1.06M  1.10MB/s    in 1.0s    \r\n",
      "\r\n",
      "2022-12-14 13:10:00 (1.10 MB/s) - ‘datasets/tiny-shakespeare.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir datasets\n",
    "!wget -P datasets/ https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PySpark\n",
    "\n",
    "Como se discutió en las clases, cada aplicación Spark tiene un controlador(driver) Spark. Es el programa que declara las transformaciones y acciones en los RDD de datos y envía dichas solicitudes al administrador del clúster. En realidad, el controlador es el programa que crea SparkContext, conectándose a un administrador de clúster determinado, como Spark Master, YARN u otros. Los ejecutores ejecutan código de usuario, ejecutan cálculos y pueden almacenar datos en caché para su aplicación. SparkContext creará un trabajo que se dividirá en etapas. Las etapas se dividen en tareas programadas por SparkContext en un ejecutor.\n",
    "\n",
    "Al iniciar PySpark con el comando pyspark o usar un cuaderno bien configurado (como este), SparkContext se crea automáticamente en la variable sc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<SparkContext master=local[*] appName=pyspark-shell>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m input_file \u001B[38;5;241m=\u001B[39m \u001B[43msc\u001B[49m\u001B[38;5;241m.\u001B[39mtextFile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets/tiny-shakespeare.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m num_lines \u001B[38;5;241m=\u001B[39m input_file\u001B[38;5;241m.\u001B[39mcount()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthere are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_lines\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m lines in the file\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "input_file = sc.textFile(\"datasets/tiny-shakespeare.txt\")\n",
    "num_lines = input_file.count()\n",
    "print(f\"there are {num_lines} lines in the file\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Working with the Apache Spark Web UI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La interfaz de usuario web de Apache Spark se puede utilizar para diseccionar la vida de la ejecución de un trabajo.\n",
    "\n",
    "* Verá información sobre las máquinas de trabajo de su clúster (cantidad de núcleos, memoria disponible, ...) y una lista de aplicaciones. Verá una aplicación en ejecución, correspondiente al shell pyspark conectado a su Jupyter Notebook. Haga clic en su ID de aplicación para inspeccionar todos los trabajos que ha ejecutado esta aplicación.\n",
    "* Llegará a una página general con un resumen de su aplicación de shell pyspark.\n",
    "Siga la interfaz de usuario de detalles de la aplicación.\n",
    "\n",
    "Si es la primera vez que ejecuta la celda Notebook con el trabajo simple de \"recuento de líneas\", verá un solo elemento en la lista de trabajos. Preste atención al nombre del trabajo: corresponde al nombre de la Acción que disparó el trabajo, es decir, la acción de conteo. En este nivel, solo ve un resumen de trabajo aproximado: su tiempo de envío, su duración, etc.\n",
    "\n",
    "* Haga clic en la descripción del trabajo. Llegará a una página con una gran cantidad de detalles sobre su trabajo, comenzando con sus etapas (recuerde, los trabajos están hechos de etapas, que a su vez están hechas de tareas).\n",
    "* Expanda las secciones sobre la línea de tiempo del evento y la visualización de DAG.\n",
    "* A continuación, haga clic en la etapa del trabajo con el mismo nombre que el recuento de acciones que especificamos en nuestro código"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preguntas\n",
    "Usando el Web UI de Spark, responda las siguientes preguntas:\n",
    "\n",
    "* ¿Cuántas tareas (tasks) se ejecutaron en esta etapa (stage)?\n",
    "* ¿Cuántos recursos se utilizaron para ejecutar esta etapa?\n",
    "* ¿Cuánto tiempo tomó esta etapa?\n",
    "* ¿Cuánto tiempo tomó la acción de conteo?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicios"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ejercicio 1: Contar palabras\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el siguiente ejemplo, estamos interesados en las 10 palabras principales en términos de frecuencia de aparición. Para hacerlo, usamos un pequeño archivo de texto como entrada y deseamos trazar la frecuencia de términos de esas 10 palabras principales usando Matplotlib.\n",
    "\n",
    "Primero, usando el método textFile de SparkContext sc, creamos un RDD de strings. Cada string en el RDD es representativa de una línea en el archivo de texto. De forma vaga, podemos pensar que el primer RDD es un RDD de líneas de texto.\n",
    "\n",
    "Debido a que trabajamos en el alcance de las palabras, tenemos que transformar una línea del RDD actual en múltiples palabras, cada palabra es un objeto del nuevo RDD. Esto se hace usando la función flatMap.\n",
    "\n",
    "Luego, una función de mapa transforma cada palabra en el RDD en una sola tupla con 2 componentes: la palabra en sí y la cuenta de 1. Como habrás adivinado, este es un PairRDD, donde cada objeto es un par key-value.\n",
    "\n",
    "Podemos aprovechar la función **reduceByKey** para sumar todas las frecuencias de la misma palabra. Ahora, cada elemento en el RDD tiene la forma de: (palabra, frecuencia_total). Para ordenar las palabras por frecuencia de ocurrencia, podemos usar muchos enfoques. Uno de las maneras más simples es intercambiar cada tupla de modo que la frecuencia se convierta en el key y usar la función sortByKey."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "words = sc.textFile(\"datasets/tiny-shakespeare.txt\").repartition(8)\\\n",
    "            .flatMap(lambda line: line.split(\" \"))\\\n",
    "            .map(lambda word: (word, 1))\\\n",
    "            .reduceByKey(lambda a, b: a + b)\\\n",
    "            .map(lambda x: (x[1], x[0]))\\\n",
    "            .sortByKey(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preguntas\n",
    "\n",
    "* ¿Cuál es el tamaño del archivo de entrada?\n",
    "* ¿En cuántos bloques se divide el archivo de entrada? ¿Cuál es el tamaño del bloque?\n",
    "* ¿Cuántas tareas(tasks) se ejecutan en paralelo?\n",
    "* ¿Cuántos trabajos (jobs) se iniciaron tras la ejecución del código anterior? ¿Por qué (tenga en cuenta que no hay acciones!)?\n",
    "* ¿Qué significa una etapa \"skipped\"?\n",
    "* ¿Cuál es el número de bytes shuffled? ¿Cómo se compara esto con el número de bytes de entrada?\n",
    "* ¿Cree que Spark está haciendo un buen trabajo al equilibrar la carga entre los trabajadores? ¿Qué puede salir mal con el equilibrio de carga?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora tomamos las 10 palabras principales. Para hacerlo, usamos la función take. Esta función es una acción, por lo que inicia un trabajo. El trabajo se ejecuta en paralelo en el clúster. La función take devuelve una lista de tuplas (frecuencia, palabra) en el driver. El driver es la máquina que ejecuta el código Python. En nuestro caso, el driver es el nodo maestro del clúster."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7241, ''), (5437, 'the'), (4403, 'I'), (3923, 'to'), (3678, 'and'), (3275, 'of'), (2677, 'my'), (2610, 'a'), (2130, 'you'), (2073, 'in')]\n"
     ]
    }
   ],
   "source": [
    "top10 = words.take(10)\n",
    "print(top10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ATENCIÓN**: La accion de colectar puede ser problemática. De hecho, un RDD puede tener un tamaño muy grande (¡es por eso que se distribuyen en varias máquinas en primer lugar!) y, por lo tanto, ¡podría agotar la RAM disponible en la máquina que ejecuta el controlador!. Es por eso que es mejor usar la función take, que devuelve una lista de tamaño fijo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ejercicio 2: Flights\n",
    "\n",
    "Tenemos un archivo CSV con datos de vuelos. El archivo contiene 29 columnas, que son:\n",
    "\n",
    "* **Year**: 1987-2008\n",
    "* **Month**: 1-12\n",
    "* **DayofMonth**: 1-31\n",
    "* **DayOfWeek**: 1 (Monday) - 7 (Sunday)\n",
    "* **DepTime**: actual departure time (local, hhmm)\n",
    "* **CRSDepTime**: scheduled departure time (local, hhmm)\n",
    "* **ArrTime**: actual arrival time (local, hhmm)\n",
    "* **CRSArrTime**: scheduled arrival time (local, hhmm)\n",
    "* **UniqueCarrier**: unique carrier code\n",
    "* **FlightNum**: flight number\n",
    "* **TailNum**: plane tail number\n",
    "* **ActualElapsedTime**: in minutes\n",
    "* **CRSElapsedTime**: in minutes\n",
    "* **AirTime**: in minutes\n",
    "* **ArrDelay**: arrival delay, in minutes\n",
    "* **DepDelay**: departure delay, in minutes\n",
    "* **Origin**: origin IATA airport code\n",
    "* **Dest**: destination IATA airport code\n",
    "* **Distance**: in miles\n",
    "* **TaxiIn**: taxi in time, in minutes\n",
    "* **TaxiOut**: taxi out time in minutes\n",
    "* **Cancelled**: was the flight cancelled? (1 = yes)\n",
    "* **CancellationCode**: reason for cancellation (A = carrier, B = weather, C = NAS, D = security)\n",
    "* **Diverted**: 1 = yes, 0 = no\n",
    "* **CarrierDelay**: in minutes\n",
    "* **WeatherDelay**: in minutes\n",
    "* **NASDelay**: in minutes\n",
    "* **SecurityDelay**: in minutes\n",
    "* **LateAircraftDelay**: in minutes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ejercicio 2.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este ejercicio, estamos interesados solo en las siguientes columnas:\n",
    "\n",
    "* **CRSDepTime**: scheduled departure time (local, hhmm)\n",
    "* **UniqueCarrier**: unique carrier code\n",
    "\n",
    "Asuma que un night flight es un vuelo que sale después de las 19:00.\n",
    "\n",
    "Responda las siguientes preguntas:\n",
    "\n",
    "* ¿Cuántos vuelos nocturnos hay en total?\n",
    "* ¿Cuántos vuelos nocturnos hay por cada aerolínea? Muestre los 5 primeros resultados en terminos de volumen de vuelos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" YOUR CODE HERE \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of flights: 1311826\n"
     ]
    }
   ],
   "source": [
    "# how many night flights are there in total?\n",
    "data = sc.textFile(\"datasets/airline/1987.csv\")\n",
    "header = data.first()\n",
    "data = data.filter(lambda line: line != header)\n",
    "total_flights = data.count()\n",
    "print(\"Total number of flights: {}\".format(total_flights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of night flights: 208331\n",
      "Top 5 carriers with the most night flights: [('DL', 32972), ('AA', 25676), ('UA', 21954), ('EA', 20403), ('PI', 19200)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "data = sc.textFile(\"datasets/airline/1987.csv\")\n",
    "\n",
    "def extract_CRSDepTime_Carier(line):\n",
    "    cols = line.split(\",\")\n",
    "    return (int(cols[5]), cols[8])\n",
    "\n",
    "\n",
    "header = data.first()\n",
    "data_without_header = data.filter(lambda line: line != header)\n",
    "\n",
    "# Pregunta 1: ¿Cuántos vuelos nocturnos hay en total?\n",
    "mapped_data = data_without_header.map(extract_CRSDepTime_Carier).cache()\n",
    "\n",
    "night_flights = mapped_data.filter(lambda x: 1900 < x[0] < 2359)\n",
    "\n",
    "\n",
    "print(\"Total number of night flights: {}\".format(night_flights.count()))\n",
    "\n",
    "# Pregunta 2: ¿Cuántos vuelos nocturnos hay por cada aerolínea? Muestre los 5 primeros resultados en terminos de volumen de vuelos.\n",
    "night_flights_per_carrier = night_flights.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b)\n",
    "print(f\"Top 5 carriers with the most night flights: {night_flights_per_carrier.takeOrdered(5, key=lambda x: -x[1])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['N240WN',\n 'N215WN',\n 'N792SW',\n '',\n 'N631SW',\n 'N341SW',\n 'N689SW',\n 'N295WN',\n 'N272WN',\n 'N461WN',\n 'N690SW',\n 'N476WN',\n 'N707SA',\n 'N346SW',\n 'N399WN',\n 'N387SW',\n 'N685SW',\n 'N663SW',\n 'N238WN',\n 'N309SW']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "# show plane tail numbers\n",
    "data = sc.textFile(\"datasets/airline/2008.csv\")\n",
    "def extract_TailNum(line):\n",
    "    cols = line.split(\",\")\n",
    "    return cols[10]\n",
    "header = data.first()\n",
    "data_without_header = data.filter(lambda line: line != header)\n",
    "data_without_header.map(extract_TailNum).distinct().take(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ejercicio 2.2\n",
    "\n",
    "En este ejercicio, considerando las siguientes columnas:\n",
    "\n",
    "* **UniqueCarrier**: unique carrier code\n",
    "* **DepDelay**: departure delay, in minutes\n",
    "\n",
    "Nombre de la aerolinea ordenar ascendente, mostrar 5\n",
    "\n",
    "Se les pide responder las siguientes preguntas:\n",
    "* Calcular el retraso promedio por aerolínea.\n",
    "* Calcular el retraso promedio por aerolínea y por mes.\n",
    "* Calcular el retraso promedio por aerolínea y por día de la semana."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" YOUR CODE HERE \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delay per carrier: [('UA', 21.0218020806202), ('PA (1)', 23.875240980446158), ('AS', 24.995272186951237), ('EA', 35.032679013714834), ('PI', 12.83028809963731)]\n",
      "Average delay per carrier and month: [(('UA', 10), 15.720145762544936), (('PA (1)', 10), 20.55041518386714), (('AS', 10), 25.47847533632287), (('PS', 11), 19.033396430502975), (('NW', 11), 18.80029207740051), (('DL', 11), 16.757431883314084), (('TW', 12), 22.16971279373368), (('WN', 12), 24.30888464562507), (('HP', 12), 20.068478829064297), (('CO', 12), 46.382716049382715), (('AA', 12), 15.6775821942505), (('EA', 10), 29.092371192712783), (('PI', 10), 8.272955808414924), (('US', 10), 10.594040164111423), (('TW', 11), 16.13349434625096), (('WN', 11), 21.299598809369744), (('HP', 11), 16.095202815336172), (('CO', 11), 29.26831385642738), (('AA', 11), 10.898827148625264), (('PS', 12), 27.18508565670138)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "data = sc.textFile(\"datasets/airline/1987.csv\")\n",
    "\n",
    "def extract_Carrier_Delay(line):\n",
    "    cols = line.split(\",\")\n",
    "    if cols[15] == \"NA\":\n",
    "        return (cols[8], 0)\n",
    "    else:\n",
    "        return (cols[8], int(cols[15]))\n",
    "\n",
    "header = data.first()\n",
    "data_without_header = data.filter(lambda line: line != header)\n",
    "\n",
    "# Pregunta 1: Calcular el retraso promedio por aerolínea.\n",
    "carrier_delay = data_without_header.map(extract_Carrier_Delay).cache()\n",
    "\n",
    "# filter out the flights with no delay\n",
    "carrier_delay = carrier_delay.filter(lambda x: x[1] > 0)\n",
    "carrier_delay_avg = carrier_delay.mapValues(lambda x: (x, 1)).reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda x: x[0] / x[1])\n",
    "print(f\"Average delay per carrier: {carrier_delay_avg.take(5)}\")\n",
    "\n",
    "# Pregunta 2: Calcular el retraso promedio por aerolínea y por mes.\n",
    "def extract_Carrier_Month_Delay(line):\n",
    "    cols = line.split(\",\")\n",
    "    if cols[15] == \"NA\":\n",
    "        return ((cols[8], int(cols[1])), 0)\n",
    "    else:\n",
    "        return ((cols[8], int(cols[1])), int(cols[15]))\n",
    "\n",
    "carrier_month_delay = data_without_header.map(extract_Carrier_Month_Delay).cache()\n",
    "\n",
    "# filter out the flights with no delay // order by Nombre Aerolinea y take 20\n",
    "carrier_month_delay = carrier_month_delay.filter(lambda x: x[1] > 0)\n",
    "carrier_month_delay_avg = carrier_month_delay.mapValues(lambda x: (x, 1)).reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])).mapValues(lambda x: x[0] / x[1]).sortByKey(ascending=True)\n",
    "print(f\"Average delay per carrier and month: {carrier_month_delay_avg.take(20)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ejercicio 2.3\n",
    "\n",
    "En este ejercicio, considerando las siguientes columnas:\n",
    "\n",
    "* **UniqueCarrier**: unique carrier code, Columna 8\n",
    "* **Cancelled**: was the flight cancelled? (1 = yes), Columna 21\n",
    "* **CancelationCode**: reason for cancellation (A = carrier, B = weather, C = NAS, D = security), Columna 22\n",
    "\n",
    "Se les pide responder las siguientes preguntas:\n",
    "\n",
    "* ¿Cuantos vuelos fueron cancelados en 1987? y en 2008?\n",
    "\n",
    "Responder las preguntas siguientes utilizando el año 2008:\n",
    "\n",
    "* ¿Cuál es la razón más común de cancelación de vuelos?\n",
    "* Por cada aerolínea, ¿cuál es la razón más común de cancelación de vuelos? Muestre los 5 primeros resultados en terminos de volumen de vuelos.\n",
    "* ¿Cuantos vuelos fueron cancelados por cada aerolínea, por razones de mal tiempo? Muestre los 5 primeros resultados en terminos de volumen de vuelos.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" YOUR CODE HERE \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cancelled flights in 1987: 19685\n",
      "Total number of cancelled flights in 2008: 64442\n",
      "Most common reason for cancellation in 2008: [('A', 26075)]\n",
      "Most common reason for cancellation per carrier in 2008: [('YV', ('A', 2946)), ('NW', ('A', 503)), ('XE', ('B', 2271)), ('HA', ('A', 112)), ('AS', ('A', 575))]\n",
      "Number of flights cancelled per carrier due to bad weather in 2008: [('MQ', 4490), ('AA', 3274), ('OO', 2397), ('XE', 2271), ('OH', 2020)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Pregunta 1: ¿Cuantos vuelos fueron cancelados en 1987? y en 2008?\n",
    "data_1987 = sc.textFile(\"datasets/airline/1987.csv\")\n",
    "data_2008 = sc.textFile(\"datasets/airline/2008.csv\")\n",
    "\n",
    "def extract_Carrier_Cancelled_CancelCode(line):\n",
    "    cols = line.split(\",\")\n",
    "    return (cols[8], (int(cols[21]), cols[22]))\n",
    "\n",
    "def clear_header(data):\n",
    "    header = data.first()\n",
    "    data_without_header = data.filter(lambda line: line != header)\n",
    "    return data_without_header\n",
    "\n",
    "def filter_cancelled(data):\n",
    "    return data.filter(lambda x: x[1][0] == 1)\n",
    "\n",
    "data_without_header = clear_header(data_1987)\n",
    "cancelled_flights_1987 = filter_cancelled(data_without_header.map(extract_Carrier_Cancelled_CancelCode))\n",
    "print(f\"Total number of cancelled flights in 1987: {cancelled_flights_1987.count()}\")\n",
    "\n",
    "data_without_header = clear_header(data_2008)\n",
    "cancelled_flights_2008 = filter_cancelled(data_without_header.map(extract_Carrier_Cancelled_CancelCode))\n",
    "print(f\"Total number of cancelled flights in 2008: {cancelled_flights_2008.count()}\")\n",
    "\n",
    "# Pregunta 2: ¿Cuál es la razón más común de cancelación de vuelos en 2008?\n",
    "cancelled_flights_2008_reduced = cancelled_flights_2008.map(lambda x: (x[1][1], 1)).reduceByKey(lambda a, b: a + b)\n",
    "print(f\"Most common reason for cancellation in 2008: {cancelled_flights_2008_reduced.takeOrdered(1, key=lambda x: -x[1])}\")\n",
    "\n",
    "# Pregunta 3: Por cada aerolínea, ¿cuál es la razón más común de cancelación de vuelos? Muestre los 5 primeros resultados en terminos de volumen de vuelos.\n",
    "cancelled_flights_2008_reduced = cancelled_flights_2008.map(lambda x: ((x[0], x[1][1]), 1)).reduceByKey(lambda a, b: a + b)\n",
    "cancelled_flights_2008_reduced = cancelled_flights_2008_reduced.map(lambda x: (x[0][0], (x[0][1], x[1]))).groupByKey()\n",
    "cancelled_flights_2008_reduced = cancelled_flights_2008_reduced.mapValues(lambda x: sorted(x, key=lambda y: -y[1])[0])\n",
    "print(f\"Most common reason for cancellation per carrier in 2008: {cancelled_flights_2008_reduced.take(5)}\")\n",
    "\n",
    "# Pregunta 4: ¿Cuantos vuelos fueron cancelados por cada aerolínea, por razones de mal tiempo? Muestre los 5 primeros resultados en terminos de volumen de vuelos.\n",
    "cancelled_flights_2008_reduced = cancelled_flights_2008.filter(lambda x: x[1][1] == \"B\").map(lambda x: (x[0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "print(f\"Number of flights cancelled per carrier due to bad weather in 2008: {cancelled_flights_2008_reduced.takeOrdered(5, key=lambda x: -x[1])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}